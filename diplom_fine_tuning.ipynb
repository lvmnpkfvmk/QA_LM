{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import openai\n",
    "import json\n",
    "import ijson\n",
    "import os\n",
    "import tiktoken\n",
    "from collections import defaultdict\n",
    "\n",
    "openai.api_key = \"\"\n",
    "\n",
    "openai.base_url = \"https://api.vsegpt.ru:6070/v1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_conversation(question, answer, system_message):\n",
    "    messages = []\n",
    "    if system_message:\n",
    "        messages.append({\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_message\n",
    "        })\n",
    "\n",
    "    message_1 = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": question\n",
    "    }\n",
    "    message_2 = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": answer\n",
    "    }\n",
    "    messages.append(message_1)\n",
    "    messages.append(message_2)\n",
    "\n",
    "    # Creating the final output dictionary\n",
    "    output_dict = {\n",
    "        \"messages\": messages\n",
    "    }\n",
    "\n",
    "    return output_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('archive/n_annotated_wd_data_test_answerable.csv')\n",
    "df_train = pd.read_csv('archive/n_annotated_wd_data_train_answerable.csv')\n",
    "df_valid = pd.read_csv('archive/n_annotated_wd_data_valid_answerable.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a question answering system. Answer shortly in 1-3 words\"\n",
    "dataset = []\n",
    "\n",
    "for question, answer in zip(df_train['q'][:200], df_train['e2']):\n",
    "    record = convert_conversation(question, answer, system_message)\n",
    "    dataset.append(record)\n",
    "    \n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a question answering system. Answer shortly in 1-3 words\"\n",
    "validation = []\n",
    "\n",
    "for question, answer in zip(df_valid['q'][:200], df_valid['e2']):\n",
    "    record = convert_conversation(question, answer, system_message)\n",
    "    validation.append(record)\n",
    "    \n",
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_jsonl(conversations, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        for conversation in conversations:\n",
    "            json_line = json.dumps(conversation)\n",
    "            file.write(json_line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file_name = 'data/fine_tuning_sqwd_train.jsonl'\n",
    "validation_file_name = 'data/fine_tuning_sqwd_valid.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_jsonl(dataset, training_file_name)\n",
    "save_to_jsonl(validation, validation_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file id: file-fvifTG3NWaEo9BaRh3u9XOlN\n",
      "Validation file id: file-BZSy9DzZEFrVyGD9ug1fANDr\n"
     ]
    }
   ],
   "source": [
    "training_response = openai.File.create(\n",
    "    file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "training_file_id = training_response[\"id\"]\n",
    "\n",
    "validation_response = openai.File.create(\n",
    "    file=open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "validation_file_id = validation_response[\"id\"]\n",
    "\n",
    "print(\"Training file id:\", training_file_id)\n",
    "print(\"Validation file id:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"object\": \"fine_tuning.job\",\n",
      "  \"id\": \"ftjob-RfhzDqjrbZNKXTARaGLJBt0i\",\n",
      "  \"model\": \"gpt-3.5-turbo-0125\",\n",
      "  \"created_at\": 1714330339,\n",
      "  \"finished_at\": null,\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"organization_id\": \"org-5h4sKaWGPhS5fugds0H2RjQA\",\n",
      "  \"result_files\": [],\n",
      "  \"status\": \"validating_files\",\n",
      "  \"validation_file\": \"file-BZSy9DzZEFrVyGD9ug1fANDr\",\n",
      "  \"training_file\": \"file-fvifTG3NWaEo9BaRh3u9XOlN\",\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": \"auto\",\n",
      "    \"batch_size\": \"auto\",\n",
      "    \"learning_rate_multiplier\": \"auto\"\n",
      "  },\n",
      "  \"trained_tokens\": null,\n",
      "  \"error\": {},\n",
      "  \"user_provided_suffix\": \"sqwd-test\",\n",
      "  \"seed\": 718846123,\n",
      "  \"estimated_finish\": null,\n",
      "  \"integrations\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "suffix_name = \"sqwd-test\"\n",
    "\n",
    "\n",
    "response = openai.FineTuningJob.create(\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    suffix=suffix_name,\n",
    ")\n",
    "\n",
    "job_id = response[\"id\"]\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 585/600: training loss=0.00\n",
      "Step 586/600: training loss=0.00\n",
      "Step 587/600: training loss=0.00\n",
      "Step 588/600: training loss=0.87\n",
      "Step 589/600: training loss=0.79\n",
      "Step 590/600: training loss=0.00, validation loss=0.00\n",
      "Step 591/600: training loss=0.00\n",
      "Step 592/600: training loss=0.00\n",
      "Step 593/600: training loss=0.00\n",
      "Step 594/600: training loss=1.12\n",
      "Step 595/600: training loss=2.74\n",
      "Step 596/600: training loss=1.47\n",
      "Step 597/600: training loss=0.00\n",
      "Step 598/600: training loss=0.00\n",
      "Step 599/600: training loss=0.00\n",
      "Step 600/600: training loss=0.05, validation loss=0.00, full validation loss=1.22\n",
      "Checkpoint created at step 200 with Snapshot ID: ft:gpt-3.5-turbo-0125:personal:sqwd-test:9J4JdRJI:ckpt-step-200\n",
      "Checkpoint created at step 400 with Snapshot ID: ft:gpt-3.5-turbo-0125:personal:sqwd-test:9J4JdblX:ckpt-step-400\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0125:personal:sqwd-test:9J4Je1dk\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "response = openai.FineTuningJob.list_events(id=job_id, limit=20)\n",
    "\n",
    "events = response[\"data\"]\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event[\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "true_answers = 0\n",
    "answers = []\n",
    "for question, answer in zip(df_test['q'], df_test['e2']):\n",
    "    if i == 200:\n",
    "        break\n",
    "    messages = []\n",
    "    i += 1\n",
    "\n",
    "    prompt = \"Answer shortly in 1-3 words\"\n",
    "    # prompt = \"Отвечай наиболее коротко, 1-3 слова\"\n",
    "    # prompt = \"Ответь максимально коротко и ёмко на вопрос. Ответ приводи в именительном падеже, при этом не забывай о пунктуации.\"\n",
    "    # messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt + ' ' + question})\n",
    "    response = \"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"\", messages=messages, temperature=0, max_tokens=500\n",
    "        )\n",
    "        response = response[\"choices\"][0][\"message\"][\"content\"].lower()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        response = \"Error\"\n",
    "    answers.append({\n",
    "        \"question\": question,\n",
    "        \"answer\": response,\n",
    "        \"correct_answer\": answer.lower(),\n",
    "        \"is_correct\": answer.lower() in response\n",
    "    })\n",
    "    if answer.lower() in response:\n",
    "        true_answers += 1\n",
    "    print(i, true_answers)\n",
    "    json_data = json.dumps(answers, indent=4)\n",
    "    with open(\"questions_answers_tmp.json\", \"w\") as json_file:\n",
    "        json_file.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_files(training_file_name, training_file_id):\n",
    "    training_response = openai.File.create(\n",
    "        file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    "    )\n",
    "    training_file_id = training_response[\"id\"]\n",
    "\n",
    "    validation_response = openai.File.create(\n",
    "        file=open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    "    )\n",
    "    validation_file_id = validation_response[\"id\"]\n",
    "\n",
    "\n",
    "    print(\"Training file id:\", training_file_id)\n",
    "    print(\"Validation file id:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a question answering system. Answer shortly in 1-3 words\"\n",
    "dataset = []\n",
    "validation = []\n",
    "i = 0\n",
    "\n",
    "file_path = \"mintaka_train.json\"\n",
    "with open(file_path, 'r') as file:\n",
    "    array_items = ijson.items(file, 'item')\n",
    "    for item in array_items:\n",
    "        if i == 500:\n",
    "            break\n",
    "        messages = []\n",
    "        i += 1\n",
    "\n",
    "        question = item[\"question\"]\n",
    "        if item[\"answer\"][\"answerType\"] == \"entity\":\n",
    "            if item[\"answer\"][\"answer\"]:\n",
    "                answer = item[\"answer\"][\"answer\"][0][\"label\"]['en']\n",
    "            else:\n",
    "                answer = \"\"\n",
    "        else:\n",
    "            if len(item[\"answer\"][\"answer\"]):\n",
    "                answer = str(item[\"answer\"][\"answer\"][0])\n",
    "            else:\n",
    "                answer = \"\"\n",
    "        record = convert_conversation(question, answer, system_message)\n",
    "        dataset.append(record)\n",
    "i = 0\n",
    "    \n",
    "file_path = \"mintaka_valid.json\"\n",
    "with open(file_path, 'r') as file:\n",
    "    array_items = ijson.items(file, 'item')\n",
    "    for item in array_items:\n",
    "        if i == 500:\n",
    "            break\n",
    "        messages = []\n",
    "        i += 1\n",
    "\n",
    "        question = item[\"question\"]\n",
    "        if item[\"answer\"][\"answerType\"] == \"entity\":\n",
    "            if item[\"answer\"][\"answer\"]:\n",
    "                answer = item[\"answer\"][\"answer\"][0][\"label\"]['en']\n",
    "            else:\n",
    "                answer = \"\"\n",
    "        else:\n",
    "            if len(item[\"answer\"][\"answer\"]):\n",
    "                answer = str(item[\"answer\"][\"answer\"][0])\n",
    "            else:\n",
    "                answer = \"\"\n",
    "        record = convert_conversation(question, answer, system_message)\n",
    "        validation.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file_name = 'data/fine_tuning_mintaka_train.jsonl'\n",
    "validation_file_name = 'data/fine_tuning_mintaka_valid.jsonl'\n",
    "save_to_jsonl(dataset, training_file_name)\n",
    "save_to_jsonl(validation, validation_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file id: file-eAmkINfLKNDapjfOjRCfn3xw\n",
      "Validation file id: file-fmfZaaQqF3SUQaOMIxa7ZMAK\n"
     ]
    }
   ],
   "source": [
    "training_response = openai.File.create(\n",
    "    file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "training_file_id = training_response[\"id\"]\n",
    "\n",
    "validation_response = openai.File.create(\n",
    "    file=open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "validation_file_id = validation_response[\"id\"]\n",
    "\n",
    "print(\"Training file id:\", training_file_id)\n",
    "print(\"Validation file id:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"object\": \"fine_tuning.job\",\n",
      "  \"id\": \"ftjob-ngk4j5sQd8k4Sy1ZKh2s8aTO\",\n",
      "  \"model\": \"gpt-3.5-turbo-0125\",\n",
      "  \"created_at\": 1714369101,\n",
      "  \"finished_at\": null,\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"organization_id\": \"org-5h4sKaWGPhS5fugds0H2RjQA\",\n",
      "  \"result_files\": [],\n",
      "  \"status\": \"validating_files\",\n",
      "  \"validation_file\": \"file-fmfZaaQqF3SUQaOMIxa7ZMAK\",\n",
      "  \"training_file\": \"file-eAmkINfLKNDapjfOjRCfn3xw\",\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": \"auto\",\n",
      "    \"batch_size\": \"auto\",\n",
      "    \"learning_rate_multiplier\": \"auto\"\n",
      "  },\n",
      "  \"trained_tokens\": null,\n",
      "  \"error\": {},\n",
      "  \"user_provided_suffix\": \"mintaka-test\",\n",
      "  \"seed\": 998119998,\n",
      "  \"estimated_finish\": null,\n",
      "  \"integrations\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "suffix_name = \"mintaka-test\"\n",
    "\n",
    "\n",
    "response = openai.FineTuningJob.create(\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    suffix=suffix_name,\n",
    ")\n",
    "\n",
    "job_id = response[\"id\"]\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"mintaka_test.json\"\n",
    "with open(file_path, 'r') as file:\n",
    "    array_items = ijson.items(file, 'item')\n",
    "    \n",
    "    i = 0\n",
    "    true_answers = 0\n",
    "    answers = []\n",
    "    for item in array_items:\n",
    "        messages = []\n",
    "        i += 1\n",
    "\n",
    "        question = item[\"question\"]\n",
    "        if item[\"answer\"][\"answerType\"] == \"entity\":\n",
    "            if item[\"answer\"][\"answer\"]:\n",
    "                answer = item[\"answer\"][\"answer\"][0][\"label\"]['en']\n",
    "            else:\n",
    "                answer = \"\"\n",
    "        else:\n",
    "            if len(item[\"answer\"][\"answer\"]):\n",
    "                answer = str(item[\"answer\"][\"answer\"][0])\n",
    "            else:\n",
    "                answer = \"\"\n",
    "\n",
    "        prompt = \"Answer shortly in 1-3 words. If answer is a number, print digits\"\n",
    "        # prompt = \"Ответь максимально коротко и ёмко на вопрос. Ответ приводи в именительном падеже, при этом не забывай о пунктуации.\"\n",
    "        # messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt + ' ' + question})\n",
    "        response = \"\"\n",
    "        try:\n",
    "            response_big = openai.ChatCompletion.create(\n",
    "                model=\"\", messages=messages, temperature=0, max_tokens=500\n",
    "            )\n",
    "            response = response_big.choices[0].message.content.lower()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            response = \"\"\n",
    "        answers.append({\n",
    "            \"question\": question,\n",
    "            \"answer\": response,\n",
    "            \"correct_answer\": answer.lower(),\n",
    "            \"is_correct\": answer.lower() in response\n",
    "        })\n",
    "        if answer.lower() in response:\n",
    "            true_answers += 1\n",
    "        print(i, true_answers)\n",
    "        json_data = json.dumps(answers, indent=4)\n",
    "        with open(\"questions_answers_mintaka_chatGpt_ft.json\", \"w\") as json_file:\n",
    "            json_file.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
