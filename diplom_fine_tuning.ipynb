{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import openai\n",
    "import json\n",
    "import ijson\n",
    "import os\n",
    "import tiktoken\n",
    "from collections import defaultdict\n",
    "\n",
    "openai.api_key = \"\"\n",
    "\n",
    "openai.base_url = \"https://api.vsegpt.ru:6070/v1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_conversation(question, answer, system_message):\n",
    "    messages = []\n",
    "    if system_message:\n",
    "        messages.append({\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_message\n",
    "        })\n",
    "    message_user = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": question\n",
    "    }\n",
    "    message_assistant = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": answer\n",
    "    }\n",
    "    messages.append(message_user, message_assistant)\n",
    "    output_dict = {\n",
    "        \"messages\": messages\n",
    "    }\n",
    "    return output_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('archive/n_annotated_wd_data_test_answerable.csv')\n",
    "df_train = pd.read_csv('archive/n_annotated_wd_data_train_answerable.csv')\n",
    "df_valid = pd.read_csv('archive/n_annotated_wd_data_valid_answerable.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a question answering system. Answer shortly in 1-3 words\"\n",
    "dataset = []\n",
    "\n",
    "for question, answer in zip(df_train['q'][:200], df_train['e2']):\n",
    "    record = convert_conversation(question, answer, system_message)\n",
    "    dataset.append(record)\n",
    "    \n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a question answering system. Answer shortly in 1-3 words\"\n",
    "validation = []\n",
    "\n",
    "for question, answer in zip(df_valid['q'][:200], df_valid['e2']):\n",
    "    record = convert_conversation(question, answer, system_message)\n",
    "    validation.append(record)\n",
    "    \n",
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_jsonl(conversations, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        for conversation in conversations:\n",
    "            json_line = json.dumps(conversation)\n",
    "            file.write(json_line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file_name = 'data/fine_tuning_sqwd_train.jsonl'\n",
    "validation_file_name = 'data/fine_tuning_sqwd_valid.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_jsonl(dataset, training_file_name)\n",
    "save_to_jsonl(validation, validation_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file id: file-fvifTG3NWaEo9BaRh3u9XOlN\n",
      "Validation file id: file-BZSy9DzZEFrVyGD9ug1fANDr\n"
     ]
    }
   ],
   "source": [
    "training_response = openai.File.create(\n",
    "    file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "training_file_id = training_response[\"id\"]\n",
    "\n",
    "validation_response = openai.File.create(\n",
    "    file=open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "validation_file_id = validation_response[\"id\"]\n",
    "\n",
    "print(\"Training file id:\", training_file_id)\n",
    "print(\"Validation file id:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"object\": \"fine_tuning.job\",\n",
      "  \"id\": \"ftjob-RfhzDqjrbZNKXTARaGLJBt0i\",\n",
      "  \"model\": \"gpt-3.5-turbo-0125\",\n",
      "  \"created_at\": 1714330339,\n",
      "  \"finished_at\": null,\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"organization_id\": \"org-5h4sKaWGPhS5fugds0H2RjQA\",\n",
      "  \"result_files\": [],\n",
      "  \"status\": \"validating_files\",\n",
      "  \"validation_file\": \"file-BZSy9DzZEFrVyGD9ug1fANDr\",\n",
      "  \"training_file\": \"file-fvifTG3NWaEo9BaRh3u9XOlN\",\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": \"auto\",\n",
      "    \"batch_size\": \"auto\",\n",
      "    \"learning_rate_multiplier\": \"auto\"\n",
      "  },\n",
      "  \"trained_tokens\": null,\n",
      "  \"error\": {},\n",
      "  \"user_provided_suffix\": \"sqwd-test\",\n",
      "  \"seed\": 718846123,\n",
      "  \"estimated_finish\": null,\n",
      "  \"integrations\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "suffix_name = \"sqwd-test\"\n",
    "\n",
    "\n",
    "response = openai.FineTuningJob.create(\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    suffix=suffix_name,\n",
    ")\n",
    "\n",
    "job_id = response[\"id\"]\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 585/600: training loss=0.00\n",
      "Step 586/600: training loss=0.00\n",
      "Step 587/600: training loss=0.00\n",
      "Step 588/600: training loss=0.87\n",
      "Step 589/600: training loss=0.79\n",
      "Step 590/600: training loss=0.00, validation loss=0.00\n",
      "Step 591/600: training loss=0.00\n",
      "Step 592/600: training loss=0.00\n",
      "Step 593/600: training loss=0.00\n",
      "Step 594/600: training loss=1.12\n",
      "Step 595/600: training loss=2.74\n",
      "Step 596/600: training loss=1.47\n",
      "Step 597/600: training loss=0.00\n",
      "Step 598/600: training loss=0.00\n",
      "Step 599/600: training loss=0.00\n",
      "Step 600/600: training loss=0.05, validation loss=0.00, full validation loss=1.22\n",
      "Checkpoint created at step 200 with Snapshot ID: ft:gpt-3.5-turbo-0125:personal:sqwd-test:9J4JdRJI:ckpt-step-200\n",
      "Checkpoint created at step 400 with Snapshot ID: ft:gpt-3.5-turbo-0125:personal:sqwd-test:9J4JdblX:ckpt-step-400\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0125:personal:sqwd-test:9J4Je1dk\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "response = openai.FineTuningJob.list_events(id=job_id, limit=20)\n",
    "\n",
    "events = response[\"data\"]\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event[\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "true_answers = 0\n",
    "answers = []\n",
    "for question, answer in zip(df_test['q'], df_test['e2']):\n",
    "    if i == 200:\n",
    "        break\n",
    "    messages = []\n",
    "    i += 1\n",
    "\n",
    "    prompt = \"Answer shortly in 1-3 words\"\n",
    "    # prompt = \"Отвечай наиболее коротко, 1-3 слова\"\n",
    "    # prompt = \"Ответь максимально коротко и ёмко на вопрос. Ответ приводи в именительном падеже, при этом не забывай о пунктуации.\"\n",
    "    # messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt + ' ' + question})\n",
    "    response = \"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"\", messages=messages, temperature=0, max_tokens=500\n",
    "        )\n",
    "        response = response[\"choices\"][0][\"message\"][\"content\"].lower()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        response = \"Error\"\n",
    "    answers.append({\n",
    "        \"question\": question,\n",
    "        \"answer\": response,\n",
    "        \"correct_answer\": answer.lower(),\n",
    "        \"is_correct\": answer.lower() in response\n",
    "    })\n",
    "    if answer.lower() in response:\n",
    "        true_answers += 1\n",
    "    print(i, true_answers)\n",
    "    json_data = json.dumps(answers, indent=4)\n",
    "    with open(\"questions_answers_tmp.json\", \"w\") as json_file:\n",
    "        json_file.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_files(training_file_name, training_file_id):\n",
    "    training_response = openai.File.create(\n",
    "        file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    "    )\n",
    "    training_file_id = training_response[\"id\"]\n",
    "\n",
    "    validation_response = openai.File.create(\n",
    "        file=open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    "    )\n",
    "    validation_file_id = validation_response[\"id\"]\n",
    "\n",
    "\n",
    "    print(\"Training file id:\", training_file_id)\n",
    "    print(\"Validation file id:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a question answering system. Answer shortly in 1-3 words\"\n",
    "dataset = []\n",
    "validation = []\n",
    "i = 0\n",
    "\n",
    "file_path = \"mintaka_train_politics.json\"\n",
    "with open(file_path, 'r') as file:\n",
    "    array_items = ijson.items(file, 'item')\n",
    "    for item in array_items:\n",
    "        if i == 250:\n",
    "            break\n",
    "        messages = []\n",
    "        i += 1\n",
    "\n",
    "        question = item[\"question\"]\n",
    "        if item[\"answer\"][\"answerType\"] == \"entity\":\n",
    "            if item[\"answer\"][\"answer\"]:\n",
    "                answer = item[\"answer\"][\"answer\"][0][\"label\"]['en']\n",
    "            else:\n",
    "                answer = \"\"\n",
    "        else:\n",
    "            if len(item[\"answer\"][\"answer\"]):\n",
    "                answer = str(item[\"answer\"][\"answer\"][0])\n",
    "            else:\n",
    "                answer = \"\"\n",
    "        record = convert_conversation(question, answer, system_message)\n",
    "        dataset.append(record)\n",
    "i = 0\n",
    "    \n",
    "file_path = \"mintaka_valid_geography.json\"\n",
    "with open(file_path, 'r') as file:\n",
    "    array_items = ijson.items(file, 'item')\n",
    "    for item in array_items:\n",
    "        if i == 250:\n",
    "            break\n",
    "        messages = []\n",
    "        i += 1\n",
    "\n",
    "        question = item[\"question\"]\n",
    "        if item[\"answer\"][\"answerType\"] == \"entity\":\n",
    "            if item[\"answer\"][\"answer\"]:\n",
    "                answer = item[\"answer\"][\"answer\"][0][\"label\"]['en']\n",
    "            else:\n",
    "                answer = \"\"\n",
    "        else:\n",
    "            if len(item[\"answer\"][\"answer\"]):\n",
    "                answer = str(item[\"answer\"][\"answer\"][0])\n",
    "            else:\n",
    "                answer = \"\"\n",
    "        record = convert_conversation(question, answer, system_message)\n",
    "        validation.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file_name = 'data/fine_tuning_mintaka_politics_train.jsonl'\n",
    "validation_file_name = 'data/fine_tuning_mintaka_politics_valid.jsonl'\n",
    "save_to_jsonl(dataset, training_file_name)\n",
    "save_to_jsonl(validation, validation_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file id: file-M0EWplJcdCB1sUseBcxTVnsj\n",
      "Validation file id: file-SmHbfecfpyTAcjIzdtHZ8YPv\n"
     ]
    }
   ],
   "source": [
    "training_response = openai.File.create(\n",
    "    file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "training_file_id = training_response[\"id\"]\n",
    "\n",
    "validation_response = openai.File.create(\n",
    "    file=open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "validation_file_id = validation_response[\"id\"]\n",
    "\n",
    "print(\"Training file id:\", training_file_id)\n",
    "print(\"Validation file id:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"object\": \"fine_tuning.job\",\n",
      "  \"id\": \"ftjob-mGfZiHkRx7pw3sI3B7YTd64e\",\n",
      "  \"model\": \"gpt-3.5-turbo-1106\",\n",
      "  \"created_at\": 1714846153,\n",
      "  \"finished_at\": null,\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"organization_id\": \"org-5h4sKaWGPhS5fugds0H2RjQA\",\n",
      "  \"result_files\": [],\n",
      "  \"status\": \"validating_files\",\n",
      "  \"validation_file\": \"file-SmHbfecfpyTAcjIzdtHZ8YPv\",\n",
      "  \"training_file\": \"file-M0EWplJcdCB1sUseBcxTVnsj\",\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": \"auto\",\n",
      "    \"batch_size\": \"auto\",\n",
      "    \"learning_rate_multiplier\": \"auto\"\n",
      "  },\n",
      "  \"trained_tokens\": null,\n",
      "  \"error\": {},\n",
      "  \"user_provided_suffix\": \"mintaka-politics\",\n",
      "  \"seed\": 2024674706,\n",
      "  \"estimated_finish\": null,\n",
      "  \"integrations\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "suffix_name = \"mintaka-politics\"\n",
    "\n",
    "\n",
    "response = openai.FineTuningJob.create(\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    suffix=suffix_name,\n",
    ")\n",
    "\n",
    "job_id = response[\"id\"]\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "5 4\n",
      "6 5\n",
      "7 6\n",
      "8 6\n",
      "9 7\n",
      "10 8\n",
      "11 9\n",
      "12 10\n",
      "13 11\n",
      "14 12\n",
      "15 12\n",
      "16 13\n",
      "17 14\n",
      "18 15\n",
      "19 16\n",
      "20 17\n",
      "21 18\n",
      "22 19\n",
      "23 20\n",
      "24 21\n",
      "25 22\n",
      "26 23\n",
      "27 24\n",
      "28 24\n",
      "29 24\n",
      "30 25\n",
      "31 25\n",
      "32 26\n",
      "33 27\n",
      "34 27\n",
      "35 27\n",
      "36 28\n",
      "37 29\n",
      "38 29\n",
      "39 30\n",
      "40 31\n",
      "41 32\n",
      "42 32\n",
      "43 32\n",
      "44 33\n",
      "45 33\n",
      "46 34\n",
      "47 34\n",
      "48 35\n",
      "49 36\n",
      "50 37\n",
      "51 38\n",
      "52 38\n",
      "53 39\n",
      "54 39\n",
      "55 39\n",
      "56 39\n",
      "57 40\n",
      "58 41\n",
      "59 41\n",
      "60 41\n",
      "61 41\n",
      "62 42\n",
      "63 43\n",
      "64 43\n",
      "65 44\n",
      "66 45\n",
      "67 46\n",
      "68 46\n",
      "69 47\n",
      "70 47\n",
      "71 47\n",
      "72 47\n",
      "73 48\n",
      "74 49\n",
      "75 50\n",
      "76 51\n",
      "77 52\n",
      "78 52\n",
      "79 53\n",
      "80 54\n",
      "81 54\n",
      "82 55\n",
      "83 55\n",
      "84 55\n",
      "85 55\n",
      "86 55\n",
      "87 55\n",
      "88 55\n",
      "89 56\n",
      "90 57\n",
      "91 57\n",
      "92 57\n",
      "93 57\n",
      "94 58\n",
      "95 59\n",
      "96 60\n",
      "97 60\n",
      "98 61\n",
      "99 62\n",
      "100 63\n",
      "101 64\n",
      "102 65\n",
      "103 66\n",
      "104 67\n",
      "105 67\n",
      "106 68\n",
      "107 69\n",
      "108 70\n",
      "109 70\n",
      "110 70\n",
      "111 70\n",
      "112 71\n",
      "113 72\n",
      "114 72\n",
      "115 73\n",
      "116 74\n",
      "117 75\n",
      "118 76\n",
      "119 77\n",
      "120 78\n",
      "121 79\n",
      "122 80\n",
      "123 81\n",
      "124 81\n",
      "125 82\n",
      "126 82\n",
      "127 83\n",
      "128 84\n",
      "129 84\n",
      "130 85\n",
      "131 86\n",
      "132 87\n",
      "133 88\n",
      "134 89\n",
      "135 90\n",
      "136 91\n",
      "137 92\n",
      "138 93\n",
      "139 94\n",
      "140 95\n",
      "141 96\n",
      "142 97\n",
      "143 98\n",
      "144 99\n",
      "145 100\n",
      "146 101\n",
      "147 102\n",
      "148 103\n",
      "149 103\n",
      "150 104\n",
      "151 105\n",
      "152 106\n",
      "153 107\n",
      "154 108\n",
      "155 109\n",
      "156 110\n",
      "157 110\n",
      "158 110\n",
      "159 111\n",
      "160 111\n",
      "161 112\n",
      "162 112\n",
      "163 113\n",
      "164 113\n",
      "165 113\n",
      "166 114\n",
      "167 115\n",
      "168 115\n",
      "169 116\n",
      "170 116\n",
      "171 116\n",
      "172 117\n",
      "173 117\n",
      "174 118\n",
      "175 118\n",
      "176 119\n",
      "177 120\n",
      "178 121\n",
      "179 122\n",
      "180 122\n",
      "181 123\n",
      "182 123\n",
      "183 123\n",
      "184 124\n",
      "185 125\n",
      "186 126\n",
      "187 127\n",
      "188 127\n",
      "189 128\n",
      "190 129\n",
      "191 130\n",
      "192 131\n",
      "193 131\n",
      "194 131\n",
      "195 132\n",
      "196 133\n",
      "197 134\n",
      "198 134\n",
      "199 134\n",
      "200 134\n",
      "201 135\n",
      "202 136\n",
      "203 137\n",
      "204 138\n",
      "205 139\n",
      "206 140\n",
      "207 141\n",
      "208 142\n",
      "209 143\n",
      "210 143\n",
      "211 144\n",
      "212 145\n",
      "213 146\n",
      "214 147\n",
      "215 148\n",
      "216 149\n",
      "217 150\n",
      "218 151\n",
      "219 151\n",
      "220 152\n",
      "221 153\n",
      "222 153\n",
      "223 154\n",
      "224 154\n",
      "225 154\n",
      "226 155\n",
      "227 156\n",
      "228 157\n",
      "229 158\n",
      "230 159\n",
      "231 159\n",
      "232 160\n",
      "233 161\n",
      "234 162\n",
      "235 162\n",
      "236 162\n",
      "237 162\n",
      "238 162\n",
      "239 162\n",
      "240 163\n",
      "241 164\n",
      "242 165\n",
      "243 165\n",
      "244 166\n",
      "245 167\n",
      "246 167\n",
      "247 167\n",
      "248 168\n",
      "249 168\n",
      "250 169\n",
      "251 170\n",
      "252 171\n",
      "253 172\n",
      "254 173\n",
      "255 174\n",
      "256 175\n",
      "257 176\n",
      "258 177\n",
      "259 178\n",
      "260 179\n",
      "261 180\n",
      "262 181\n",
      "263 182\n",
      "264 183\n",
      "265 183\n",
      "266 184\n",
      "267 185\n",
      "268 186\n",
      "269 187\n",
      "270 188\n",
      "271 189\n",
      "272 190\n",
      "273 190\n",
      "274 191\n",
      "275 192\n",
      "276 193\n",
      "277 194\n",
      "278 194\n",
      "279 195\n",
      "280 196\n",
      "281 197\n",
      "282 198\n",
      "283 199\n",
      "284 200\n",
      "285 201\n",
      "286 202\n",
      "287 203\n",
      "288 204\n",
      "289 205\n",
      "290 206\n",
      "291 207\n",
      "292 208\n",
      "293 209\n",
      "294 210\n",
      "295 211\n",
      "296 212\n",
      "297 213\n",
      "298 214\n",
      "299 215\n",
      "300 215\n",
      "301 215\n",
      "302 216\n",
      "303 216\n",
      "304 216\n",
      "305 216\n",
      "306 217\n",
      "307 217\n",
      "308 217\n",
      "309 218\n",
      "310 219\n",
      "311 220\n",
      "312 220\n",
      "313 220\n",
      "314 220\n",
      "315 220\n",
      "316 220\n",
      "317 220\n",
      "318 221\n",
      "319 221\n",
      "320 222\n",
      "321 222\n",
      "322 223\n",
      "323 224\n",
      "324 225\n",
      "325 226\n",
      "326 227\n",
      "327 228\n",
      "328 229\n",
      "329 230\n",
      "330 231\n",
      "331 232\n",
      "332 233\n",
      "333 234\n",
      "334 235\n",
      "335 236\n",
      "336 237\n",
      "337 237\n",
      "338 238\n",
      "339 238\n",
      "340 239\n",
      "341 240\n",
      "342 240\n",
      "343 241\n",
      "344 242\n",
      "345 243\n",
      "346 243\n",
      "347 243\n",
      "348 244\n",
      "349 245\n",
      "350 246\n",
      "351 247\n",
      "352 248\n",
      "353 249\n",
      "354 250\n",
      "355 250\n",
      "356 251\n",
      "357 252\n",
      "358 253\n",
      "359 253\n",
      "360 254\n",
      "361 254\n",
      "362 255\n",
      "363 256\n",
      "364 256\n",
      "365 256\n",
      "366 257\n",
      "367 258\n",
      "368 259\n",
      "369 260\n",
      "370 260\n",
      "371 261\n",
      "372 261\n",
      "373 262\n",
      "374 263\n",
      "375 264\n",
      "376 264\n",
      "377 264\n",
      "378 265\n",
      "379 265\n",
      "380 266\n",
      "381 267\n",
      "382 268\n",
      "383 269\n",
      "384 270\n",
      "385 270\n",
      "386 270\n",
      "387 270\n",
      "388 271\n",
      "389 272\n",
      "390 273\n",
      "391 274\n",
      "392 274\n",
      "393 275\n",
      "394 275\n",
      "395 276\n",
      "396 277\n",
      "397 278\n",
      "398 278\n",
      "399 278\n",
      "400 279\n",
      "401 279\n",
      "402 280\n",
      "403 281\n",
      "404 282\n",
      "405 283\n",
      "406 284\n",
      "407 284\n",
      "408 285\n",
      "409 286\n",
      "410 286\n",
      "411 287\n",
      "412 288\n",
      "413 289\n",
      "414 290\n",
      "415 290\n",
      "416 291\n",
      "417 292\n",
      "418 293\n",
      "419 294\n",
      "420 294\n",
      "421 295\n",
      "422 295\n",
      "423 296\n",
      "424 297\n",
      "425 298\n",
      "426 298\n",
      "427 298\n",
      "428 299\n",
      "429 300\n",
      "430 300\n",
      "431 300\n",
      "432 300\n",
      "433 300\n",
      "434 300\n",
      "435 301\n",
      "436 301\n",
      "437 302\n",
      "438 303\n",
      "439 304\n",
      "440 304\n",
      "441 305\n",
      "442 306\n",
      "443 307\n",
      "444 307\n",
      "445 307\n",
      "446 308\n",
      "447 309\n",
      "448 310\n",
      "449 311\n",
      "450 311\n",
      "451 312\n",
      "452 312\n",
      "453 312\n",
      "454 313\n",
      "455 314\n",
      "456 315\n",
      "457 316\n",
      "458 317\n",
      "459 318\n",
      "460 319\n",
      "461 320\n",
      "462 321\n",
      "463 322\n",
      "464 322\n",
      "465 323\n",
      "466 323\n",
      "467 324\n",
      "468 324\n",
      "469 324\n",
      "470 325\n",
      "471 326\n",
      "472 327\n",
      "473 328\n",
      "474 329\n",
      "475 329\n",
      "476 330\n",
      "477 331\n",
      "478 332\n",
      "479 333\n",
      "480 334\n",
      "481 334\n",
      "482 335\n",
      "483 336\n",
      "484 337\n",
      "485 338\n",
      "486 338\n",
      "487 339\n",
      "488 339\n",
      "489 339\n",
      "490 339\n",
      "491 339\n",
      "492 340\n",
      "493 341\n",
      "494 341\n",
      "495 342\n",
      "496 342\n",
      "497 343\n",
      "498 343\n",
      "499 343\n",
      "500 343\n"
     ]
    }
   ],
   "source": [
    "file_path = \"mintaka_test_politics.json\"\n",
    "with open(file_path, 'r') as file:\n",
    "    array_items = ijson.items(file, 'item')\n",
    "    \n",
    "    i = 0\n",
    "    true_answers = 0\n",
    "    answers = []\n",
    "    for item in array_items:\n",
    "        messages = []\n",
    "        i += 1\n",
    "\n",
    "        question = item[\"question\"]\n",
    "        if item[\"answer\"][\"answerType\"] == \"entity\":\n",
    "            if item[\"answer\"][\"answer\"]:\n",
    "                answer = item[\"answer\"][\"answer\"][0][\"label\"]['en']\n",
    "            else:\n",
    "                answer = \"\"\n",
    "        else:\n",
    "            if len(item[\"answer\"][\"answer\"]):\n",
    "                answer = str(item[\"answer\"][\"answer\"][0])\n",
    "            else:\n",
    "                answer = \"\"\n",
    "\n",
    "        prompt = \"Answer shortly in 1-3 words. If answer is a number, print digits\"\n",
    "        # prompt = \"Ответь максимально коротко и ёмко на вопрос. Ответ приводи в именительном падеже, при этом не забывай о пунктуации.\"\n",
    "        # messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt + ' ' + question})\n",
    "        response = \"\"\n",
    "        try:\n",
    "            response_big = openai.ChatCompletion.create(\n",
    "                model=\"ft:gpt-3.5-turbo-1106:personal:mintaka-politics:9LESlULK\", messages=messages, temperature=0, max_tokens=500\n",
    "            )\n",
    "            response = response_big.choices[0].message.content.lower()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            response = \"\"\n",
    "        answers.append({\n",
    "            \"question\": question,\n",
    "            \"answer\": response,\n",
    "            \"correct_answer\": answer.lower(),\n",
    "            \"is_correct\": answer.lower() in response\n",
    "        })\n",
    "        if answer.lower() in response:\n",
    "            true_answers += 1\n",
    "        print(i, true_answers)\n",
    "        json_data = json.dumps(answers, indent=4)\n",
    "        with open(\"questions_answers_mintaka_politics_chatGpt_ft.json\", \"w\") as json_file:\n",
    "            json_file.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"index\": 0,\n",
      "  \"message\": {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"Paris\"\n",
      "  },\n",
      "  \"logprobs\": null,\n",
      "  \"finish_reason\": \"stop\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "prompt = \"Answer shortly in 1-3 words. If answer is a number, print digits\"\n",
    "messages.append({\"role\": \"user\", \"content\": prompt + ' ' + question})            \n",
    "question = \"What is the capital of France?\"\n",
    "response_big = openai.ChatCompletion.create(\n",
    "                model=\"ft:gpt-3.5-turbo-1106:personal:mintaka-politics:9LESlULK\", messages=messages, temperature=0, max_tokens=500\n",
    "            )\n",
    "print(response_big.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
